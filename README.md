# Crack Detection â€” Semantic Segmentation (DeepLabV3+)

Pipeline de **detecciÃ³n de grietas** mediante **segmentaciÃ³n semÃ¡ntica binaria** (*crack* vs *background*), optimizado para **grietas finas/pequeÃ±as**.  
ImplementaciÃ³n principal en **PyTorch + segmentation-models-pytorch** y notebook reproducible.

---

## ğŸ“ Contenido del repositorio

Este repositorio incluye **solo**:

- `notebooks/DetecciÃ³n_de_grietas.ipynb` (pipeline completo: preparaciÃ³n, entrenamiento, validaciÃ³n e inferencia)
- Checkpoint del modelo (descarga externa)

**No** se incluyen datasets en el repositorio (son pesados). Se proveen por enlace.

---

## ğŸ“¦ Descargas (modelo y datasets)

### Modelo entrenado (checkpoint ~150 MB)
- Carpeta en Google Drive: https://drive.google.com/drive/folders/1P7U6NUe7esgJlDOMAstq0LxmOlaBcPrs?usp=sharing

**CÃ³mo usarlo**
1. Descarga el archivo del modelo desde la carpeta.
2. ColÃ³calo en tu repo en: `checkpoints/` (ej.: `checkpoints/final_crack_model.pth`)
3. En el notebook, ajusta la ruta del checkpoint si fuera necesario.

### Datasets (ZIP)
- `Dataset.zip`: https://drive.google.com/file/d/1K5XtI6jlOtGc3KOgEmu0662HT2rbG2Fu/view?usp=sharing
- `DeepCrack.zip`: https://drive.google.com/file/d/1pgiC-P5TekXht-Tl93wy3CnpgesevOve/view?usp=sharing

**ExtracciÃ³n (Colab / Linux)**
```bash
unzip -q Dataset.zip -d /content/Dataset_unzipped
unzip -q DeepCrack.zip -d /content/deepcrack_unzipped
```

> En Windows puedes extraer con 7-Zip y apuntar el notebook a las carpetas resultantes.

---


## ğŸ“Œ QuÃ© hace este repo

- Entrena un modelo de segmentaciÃ³n para detectar grietas en imÃ¡genes.
- Une mÃºltiples datasets (RGBâ€“mÃ¡scara), los normaliza y crea un Ã­ndice unificado.
- Prioriza el *recall* de grietas pequeÃ±as con:
  - **DeepLabV3+** (mejor detalle fino).
  - **Focal + Dice** (balance entre falsos negativos y estabilidad).
  - **Oversampling** de ejemplos con grietas pequeÃ±as.
  - **Post-procesamiento morfolÃ³gico** para consolidar trazos finos y filtrar ruido.

---


### Datasets usados
- DeepCrack
- Pavement Crack Datasets: CRACK500, GAPs384, CrackTree200
- CrackForest (CFD)

## ğŸ§  Enfoque

- **Tipo de tarea:** SegmentaciÃ³n semÃ¡ntica binaria
- **Entrada:** Imagen (en este proyecto se usa **grayscale** por defecto)
- **Salida:** MÃ¡scara binaria (0/1) con pÃ­xeles de grieta
- **Modelo:** DeepLabV3+ (encoder EfficientNet)
- **Loss:** FocalDiceLoss (Focal + Dice)

---

## âœ… Requisitos

### OpciÃ³n A: Google Colab (recomendado)
Este proyecto fue trabajado con flujo tipo Colab (Drive + extracciÃ³n de ZIPs).

### OpciÃ³n B: Local (Linux/Windows)
- Python 3.9+
- (Opcional) GPU CUDA para entrenar mÃ¡s rÃ¡pido

---


## âš¡ Quickstart (Colab)

1. Sube el notebook a Colab (o Ã¡brelo desde tu repo).
2. Monta Drive y descarga/ubica:
   - `Dataset.zip`
   - `DeepCrack.zip`
   - el checkpoint del modelo (si solo harÃ¡s inferencia)
3. Extrae los ZIPs (ver secciÃ³n **ğŸ“¦ Descargas**).
4. Ejecuta el notebook de arriba hacia abajo.

> Si solo quieres **inferir** (sin entrenar), ejecuta Ãºnicamente: imports â†’ carga del checkpoint â†’ bloque de inferencia/visualizaciÃ³n.


## ğŸ“¦ InstalaciÃ³n

### Dependencias mÃ­nimas
```bash
pip install -U pip
pip install segmentation-models-pytorch albumentations timm
pip install torchmetrics opencv-python-headless
pip install scikit-image scipy pandas numpy pillow pyyaml matplotlib
```

> Si vas a usar OpenCV con interfaz grÃ¡fica local, cambia `opencv-python-headless` por `opencv-python`.

---

## ğŸ—‚ï¸ Estructura sugerida del repo

> Si solo tienes el notebook, puedes dejarlo asÃ­.  
> Si quieres â€œestÃ¡ndar proyecto Pythonâ€, esta estructura es ideal.

```text
crack-detection-pipeline/
â”œâ”€ notebooks/
â”‚  â””â”€ DetecciÃ³n_de_grietas.ipynb
â””â”€ README.md
```

---

## ğŸ“š Datasets usados en este repo

Los datasets se descargan mediante los enlaces de la secciÃ³n **ğŸ“¦ Descargas (modelo y datasets)**.

- **DeepCrack** (RGB + mÃ¡scara binaria)
- **Pavement Crack Datasets** (paquete/repo), que agrupa subconjuntos:
  - **CRACK500**
  - **GAPs384**
  - **CrackTree200** (`cracktree200`)
- **CrackForest (CFD)** â€” requiere conversiÃ³n de mÃ¡scaras desde `.mat` a imagen (binaria)

---

## ğŸ“ PreparaciÃ³n de datos (flujo notebook) (flujo notebook)

### 1) Coloca los ZIPs en tu Drive (o carpeta local)
Ejemplo tÃ­pico:
- `DeepCrack.zip`
- `Dataset.zip` (colecciÃ³n con CRACK500/GAPS/CrackForest/etc.)

### 2) Extrae los ZIPs
En Colab, el notebook extrae a rutas tipo:
- `/content/deepcrack_unzipped`
- `/content/Dataset_unzipped`

### 3) CrackForest: conversiÃ³n `.mat` â†’ `.jpg/.png`
Si tienes CrackForest en `.mat`, conviÃ©rtelo a mÃ¡scaras imagen (binarias) antes de indexar.

---

## ğŸ§ª ParÃ¡metros principales (los del pipeline)

> Ajusta si cambiaste algo.

| ParÃ¡metro | Valor |
|---|---|
| Input size | 512Ã—512 |
| batch_size | 8 |
| epochs | 60 |
| optimizer | Adam |
| lr | 3e-4 |
| weight_decay | 5e-5 |
| scheduler | ReduceLROnPlateau (factor=0.5, patience=5) |
| early stopping | patience=10 |
| encoder | efficientnet-b3 |
| in_channels | 1 (grayscale) |
| classes | 1 |

---

## ğŸš€ Entrenamiento

### Si trabajas SOLO con notebook
1. Abre `notebooks/DetecciÃ³n_de_grietas.ipynb`
2. Ejecuta en orden:
   - Montaje de Drive / paths
   - ExtracciÃ³n de ZIPs
   - IndexaciÃ³n `df`
   - Split train/val
   - Entrenamiento
3. Se guardan:
   - **best checkpoint**
   - **final model**
   - curvas y figuras

### Si lo modularizas (opcional)
```bash
python -m src.train --config configs/train.yaml
```

---

## ğŸ” Inferencia

En notebook:
- Carga el checkpoint
- Corre inferencia en muestras
- Visualiza `img / gt / pred`

(En versiÃ³n modularizada)
```bash
python -m src.infer --checkpoint checkpoints/best.pth --input path/to/images --out outputs/preds
```

---

## ğŸ§¼ Post-procesamiento (grietas finas)

Se usa morfologÃ­a + filtrado por componentes conectados para:
- Unir segmentos cortados
- Reducir puntos aislados (falsos positivos)
- Favorecer trazos delgados continuos

ParÃ¡metros tÃ­picos:
- threshold = 0.3
- min_area = 10 pxÂ²
- dilate â†’ close â†’ erode â†’ filtro por Ã¡rea

---

## ğŸ“ˆ MÃ©tricas

Durante entrenamiento/validaciÃ³n:
- **IoU**
- **Dice**

BinarizaciÃ³n tÃ­pica:
- `sigmoid(pred) > 0.5`

---

## ğŸ“¦ Artefactos generados

El pipeline suele guardar:
- `training_curves.png`
- `predictions_sample.png`
- `predictions_by_size.png`
- `validation_comparison.png` (comparaciÃ³n de post-process)

> RecomendaciÃ³n: guarda todo en `outputs/` para mantener orden.

---

## ğŸ’¾ Checkpoints

Ejemplo tÃ­pico:
- `checkpoints/best_crack_model_optimized.pth`
- `checkpoints/final_crack_model.pth`

Incluye en el README (si aplica):
- dÃ³nde se guardan
- quÃ© checkpoint usar para inferencia

---

## ğŸ§¯ Troubleshooting

**1) Error: tamaÃ±os diferentes (imagen vs mÃ¡scara)**  
âœ… SoluciÃ³n: en indexaciÃ³n/loader aplica resize consistente y binarizaciÃ³n de mÃ¡scara.

**2) OpenCV falla en Colab**  
âœ… Usa `opencv-python-headless`.

**3) OOM (memoria GPU)**  
âœ… Baja `batch_size`, reduce encoder, baja resoluciÃ³n (512â†’384).

**4) Predicciones â€œmuy gruesasâ€**  
âœ… Ajusta post-procesamiento (kernel, iteraciones) y/o threshold.

---
---

## ğŸ™Œ CrÃ©ditos

Notebook base: `DetecciÃ³n_de_grietas.ipynb`  
Autor: *Espinoza Herrera Gustavo Diego*  
